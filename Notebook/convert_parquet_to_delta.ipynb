{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87be8334-6575-475f-89bf-46bb6d7b9ad4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Convert parquet to delta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1e658ff-6516-48d2-b0d9-6075d4bb9bae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6fa9880-a23c-4c7e-b526-d0e2fda5ff72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import libs\n",
    "import os\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8660098-d852-460a-9e18-7d3e4331675f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Definição de catalog e Schema\n",
    "catalog_name = \"nome_do_seu_catalog\"\n",
    "schema_name = \"nome_do_seu_schema\"\n",
    "\n",
    "# Definição do path \n",
    "base_path = f\"/Volumes/{catalog_name}/{schema_name}/raw\"\n",
    "\n",
    "# Carregamento de Catalog e Schema para o Notebook\n",
    "try:\n",
    "    spark.sql(f\"USE CATALOG {catalog_name}\")\n",
    "    spark.sql(f\"USE SCHEMA {schema_name}\")\n",
    "    print(f\"Catálogo '{catalog_name}' e schema '{schema_name}' carregados com sucesso.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar catálogo ou/e schema: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f987a6d6-7ac9-49eb-8ef5-119935b3fd2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Criação das tabelas em formato delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99681370-c72f-41c4-a492-eefead597103",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Loop no diretório para obter o caminho relativo dos arquivos parquet\n",
    "for path in os.listdir(base_path):\n",
    "    full_path = os.path.join(base_path, path)\n",
    "\n",
    "    for parquet in os.listdir(full_path):\n",
    "        parquet_file = os.path.join(full_path, parquet)\n",
    "\n",
    "        try:\n",
    "            # Leitura e escrita dos dados como tabela delta\n",
    "            spark.read.format(\"parquet\").load(parquet_file)\\\n",
    "                .write.format(\"delta\").option(\"delta.columnMapping.mode\", \"name\")\\\n",
    "                .mode(\"overwrite\").saveAsTable(f\"delta_raw_{str(parquet).replace('-', '_')}_{path}\") \n",
    "\n",
    "            print(f\"Tabela delta criada com sucesso para o arquivo: {parquet_file}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao criar tabela delta com o arquivo {parquet_file}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Convert Parquet to Delta",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
